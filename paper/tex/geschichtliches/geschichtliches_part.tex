\part{Geschichtliche Entwicklung}

Die Entwicklung künstlicher Intelligenz ist momentan eines der wohl interessantesten Themen der heutigen technologischen Ära. Durch machine Learning ist es möglich viele Bereiche zu automatisieren die man vorher nie in Betracht gezogen hatte. Dennoch hat es mich doch überrascht wie \glqq alt \grqq diese Technologie zumindest in ihren Grundzügen in manchen Teilen doch bereits ist. Ihre Anfänge fand sie schon Mitte der 50er Jahre als zum Beispiel diverse Experten auf diesem Gebiet das erste Mal zusammenkamen um im Zuge der \emph{Dartmouth Konferenz} über dieses Thema zu diskutieren. Aber auch bekannte Persönlichkeiten des Feldes, wie zum Beispiel \emph{Von Neumann} \footnote{Von Neumanns letztes Werk: zweiteiliges Manuskript über die damaligen Rechner und ihre Möglichkeiten das neuronale System zu emulieren} erkannten früh die möglichen Zusammenhänge.

Im folgenden Abschnitt werde ich etwas auf die geschichtlichen Aspekte von neuronalen Netzen eingehen. Hierbei werden insbesondere die generellen Aspekte der generellen Funktionsweise von älteren Modellen bis hin zur aktuellen Entwicklung verfolgt. Ich werde versuchen die folgenden Leitfragen in diesem Abschnitt zu beantworten: 

\begin{itemize}
\item Woher kommt Deep Learning und wie ist dieser Begriff im Kontext zur künstlichen Intelligenz einzuordnen?
\item Welche Entwicklungen hat das Neuronale Netz von damals zu heute durchgemacht?
\end{itemize}


\import{geschichtliches/mcCullochPittsNeuron/}{mpNeuron.tex}
\clearpage

\import{geschichtliches/perceptor/}{perceptor.tex}
\clearpage

\import{geschichtliches/adeline/}{adeline.tex}
\clearpage

\import{geschichtliches/convolutionalNN/}{convolutionalnn.tex}
\clearpage

\import{geschichtliches/fazit/}{fazit.tex}